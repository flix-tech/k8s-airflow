version: '2'
#env: source from parent taskfile
#vars: source from parent taskfile
env:
  REMOTE_DAG_FOLDER: /usr/local/airflow
  NAMESPACE: '{{default "default" .NAMESPACE}}'

tasks:

  default:
    cmds:
      - echo executed on $DOCKER_REGISTRY
    silent: true
    vars:
      DAG_FILE:
        sh: echo $(pwd)/dags/test.py

######## raw to master dag tasks #########
  test.deploy:
    cmds:
      - task: single_deploy
        vars:
          FILES: |-
            dags/test.py

  test.undeploy:
    cmds:
      - task: single_undeploy
        vars:
          FILES: |-
            dags/test.py

  ############## combined dags operations #############
  deploy:
    summary: |
      Deploy all dags to airflow, it does not include dags run

      It include lists of dags to deploy
    cmds:
      - task: :set.k8s.context
      - task: test.deploy

  undeploy:
    summary: |
      Undeploy all dags files and its dependencies from airflow
    cmds:
      - task: :set.k8s.context
      - task: test.undeploy

  single_deploy:
    cmds:
      - >
        {{range $f := .FILES | trim | splitLines -}}
            dir=$(dirname {{$f}})
            kubectl exec deploy/airflow -- mkdir -p $dir
            kubectl -n $NAMESPACE cp $(pwd)/{{$f}} $AIRFLOW_POD_NAME:$REMOTE_DAG_FOLDER/{{$f}}
        {{end}}
    vars:
      FILES: |-
        '{{default "__TO_BE_SET__" .FILES}}'
    env:
      AIRFLOW_POD_NAME:
        sh: kubectl -n $NAMESPACE get pods -o jsonpath="{.items[0].metadata.name}" -l app=airflow || echo "no connection"

  single_undeploy:
    cmds:
      - >
        {{range $f := .FILES | trim | splitLines -}}
            kubectl exec deploy/airflow --  rm -rfv $REMOTE_DAG_FOLDER/{{$f}}
        {{end}}
    vars:
      FILES: |-
       '{{default "__TO_BE_SET__" .FILES}}'
